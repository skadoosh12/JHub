{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNOmjchgHW4Hs5T9zNtDc+J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split as Tts\n","import string\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, f1_score"],"metadata":{"id":"MODPzII9IQZK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNy1v6TvD2Aa","executionInfo":{"status":"ok","timestamp":1673789818473,"user_tz":0,"elapsed":476,"user":{"displayName":"Harry Martin","userId":"16278557778494234606"}},"outputId":"2a6f9167-fde4-4741-dad6-12c613b1f170"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-01-15 13:36:58--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 26622 (26K) [text/plain]\n","Saving to: ‘edgar_allan_poe.txt’\n","\n","\redgar_allan_poe.txt   0%[                    ]       0  --.-KB/s               \redgar_allan_poe.txt 100%[===================>]  26.00K  --.-KB/s    in 0s      \n","\n","2023-01-15 13:36:58 (94.8 MB/s) - ‘edgar_allan_poe.txt’ saved [26622/26622]\n","\n","--2023-01-15 13:36:58--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 56286 (55K) [text/plain]\n","Saving to: ‘robert_frost.txt’\n","\n","robert_frost.txt    100%[===================>]  54.97K  --.-KB/s    in 0.001s  \n","\n","2023-01-15 13:36:58 (37.8 MB/s) - ‘robert_frost.txt’ saved [56286/56286]\n","\n"]}],"source":["!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt\n","!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt"]},{"cell_type":"markdown","source":["Extract Poem data and add to list"],"metadata":{"id":"QHCaya_MIL6R"}},{"cell_type":"code","source":["files = ['/content/edgar_allan_poe.txt', '/content/robert_frost.txt' ]\n","\n","lis_line = []\n","lis_author = []\n","\n","for author, file in enumerate(files):\n","  for line in open(file):\n","    line = line.lower().rstrip()\n","    if line:\n","      line = line.translate(str.maketrans('', '', string.punctuation))\n","      lis_line.append(line)\n","      lis_author.append(author)\n","\n","len(lis_line)"],"metadata":{"id":"WkpogQiVEesz","executionInfo":{"status":"ok","timestamp":1673789818474,"user_tz":0,"elapsed":15,"user":{"displayName":"Harry Martin","userId":"16278557778494234606"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"51bfd152-6491-4ed1-ef40-9244a2b88eeb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2154"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["Split into Training and Test Data, Add unique words to dictionary"],"metadata":{"id":"p2j3RRLoE7iD"}},{"cell_type":"code","source":["#Split into training and test set\n","lis_line_train, lis_line_test, lis_author_train, lis_author_test = Tts(lis_line, lis_author, random_state=1)\n","\n","#Add all unique words to a dictionary map\n","dict_uni_words = {'<unk>': 0}; word_count = 0\n","\n","for line in lis_line_train:\n","  for word in line.split():\n","    if word not in dict_uni_words.keys():\n","      word_count += 1\n","      dict_uni_words[word] = word_count"],"metadata":{"id":"IDVbNwT0GTm1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Map words to integers"],"metadata":{"id":"yUC-QKs0OQA_"}},{"cell_type":"code","source":["#map words to integers for training data\n","lis_line_train_int = []\n","\n","for line in lis_line_train:\n","  conv = [dict_uni_words[word] for word in line.split()]\n","  lis_line_train_int.append(conv)\n","\n","#map words to integers for test data\n","lis_line_test_int = []\n","\n","for line in lis_line_test:\n","  conv = [dict_uni_words.get(word, 0) for word in line.split()]\n","  lis_line_test_int.append(conv)"],"metadata":{"id":"AbS0lPojOPWs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lis_line_train_int[100:105]"],"metadata":{"id":"LA5mhY870kpB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673789818475,"user_tz":0,"elapsed":8,"user":{"displayName":"Harry Martin","userId":"16278557778494234606"}},"outputId":"c09bb568-f690-448f-aa8d-3a9c066a153f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[6, 388, 20, 389],\n"," [11, 390, 391, 392, 77, 34, 36, 6],\n"," [53, 26, 393],\n"," [323, 269, 236, 394, 395, 18, 6, 396],\n"," [34, 397, 323, 398, 42, 399]]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["Estimate the initial state distribution, $\\hat{\\pi}$"],"metadata":{"id":"ChdC58mjR-B2"}},{"cell_type":"code","source":["lis_pi_poe = [] ; lis_pi_frost = []\n","\n","for word_index in dict_uni_words.values():\n","  count_poe = 0; count_frost = 0\n","  \n","  for line, author in zip(lis_line_train_int, lis_author_train):\n","    if author == 0 and line[0] == word_index: #poe\n","      count_poe += 1\n","    elif author == 1 and line[0] == word_index: #frost\n","      count_frost +=1\n","\n","  lis_pi_poe.append((1 + count_poe)/(lis_author_train.count(0) + len(dict_uni_words)))\n","  lis_pi_frost.append((1 + count_frost)/(lis_author_train.count(1) + len(dict_uni_words)))\n","\n","arr_pi_poe = np.array(lis_pi_poe)\n","arr_pi_frost = np.array(lis_pi_frost)"],"metadata":{"id":"xYxLLCoQ_hXp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Estimate the state transition Matrix, $\\hat{A}_{ij}$\n","\n"],"metadata":{"id":"mfuRBb1FZ7LO"}},{"cell_type":"code","source":["arr_A_poe = np.ones((len(dict_uni_words), len(dict_uni_words) ))\n","arr_A_frost = np.ones((len(dict_uni_words), len(dict_uni_words) ))\n","\n","for line, author in zip(lis_line_train_int, lis_author_train):\n","  for prev_word, word in zip(line[0:-1],line[1:]):\n","    if author == 0: #poe\n","      arr_A_poe[prev_word, word] += 1\n","    elif author == 1: #frost\n","      arr_A_frost[prev_word, word] += 1     \n","\n","arr_A_poe /= arr_A_poe.sum(axis=1, keepdims=True)\n","arr_A_frost /= arr_A_frost.sum(axis=1, keepdims=True)"],"metadata":{"id":"HZ_eQff9cev9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculate the Prior"],"metadata":{"id":"spLhhd2UGl09"}},{"cell_type":"code","source":["p_poe = lis_author_train.count(0)/len(lis_author_train)\n","p_frost = lis_author_train.count(1)/len(lis_author_train)\n","\n","p_poe, p_frost"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C3Ejr6iUmHas","executionInfo":{"status":"ok","timestamp":1673789821121,"user_tz":0,"elapsed":4,"user":{"displayName":"Harry Martin","userId":"16278557778494234606"}},"outputId":"a5ff3d95-424c-4d8f-e734-9ab0a8129c3b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.33126934984520123, 0.6687306501547987)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Calculate Log Probabilities"],"metadata":{"id":"y79zy6Kj-FDo"}},{"cell_type":"code","source":["arr_pi_poe_log = np.log(arr_pi_poe)\n","arr_A_poe_log = np.log(arr_A_poe)\n","\n","arr_pi_frost_log = np.log(arr_pi_frost)\n","arr_A_frost_log = np.log(arr_A_frost)\n","\n","p_poe_log = np.log(p_poe)\n","p_frost_log = np.log(p_frost)"],"metadata":{"id":"jmrZUn5I-EZF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Fish:\n","    def __init__(self,var1):\n","      self.fish_var = var1\n","    \n","    def print_stuff(self):\n","      print(self.fish_var)\n","\n"],"metadata":{"id":"OdU4lQa63nCX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a  = [0.02, {'a':0.5,'b':0.6}]"],"metadata":{"id":"8wHDN37a4yFz","executionInfo":{"status":"ok","timestamp":1674234082096,"user_tz":0,"elapsed":325,"user":{"displayName":"Harry Martin","userId":"16278557778494234606"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Write classifer"],"metadata":{"id":"7T185jVoJRFH"}},{"cell_type":"code","source":["class Classifier:\n","\n","  def setup(self, logp0, logp1, logA0, logA1, logauth0, logauth1, dict_map):\n","    self.logp0 = logp0\n","    self.logp1 = logp1\n","    self.logA0 = logA0\n","    self.logA1 = logA1\n","    self.logauth0 = logauth0\n","    self.logauth1 = logauth1\n","    self.dict_map = dict_map\n","  \n","  def predict(self, lis_str):  #accepts a list of strings\n","    #encode list of strings to integer format\n","    lis_str_int = []\n","\n","    for line in lis_str:\n","      lis_line_int = []\n","      for word in line.split():\n","        lis_line_int.append(self.dict_map.get(word, 0))\n","      \n","      lis_str_int.append(lis_line_int)\n","    \n","    #Loop through each integer encoded string\n","    auth = []\n","\n","    for line in lis_str_int:\n","\n","      #for each look up estimate initial state log probability from lists, 0 poe, 1 frost\n","      logp0_poe = self.logp0[line[0]]\n","      logp1_frost = self.logp1[line[0]]\n","\n","      #for each author lookup string log probability\n","      logA0_poe = []; logA1_frost = []\n","      \n","      for i, j in zip(line[0:-1],line[1:]):\n","        logA0_poe.append(self.logA0[i,j])\n","        logA1_frost.append(self.logA1[i,j])\n","\n","      #Sum log probabilities for transition matrix\n","      logA0_poe = sum(logA0_poe)\n","      logA1_frost = sum(logA1_frost)\n","\n","      #Sum log probabilities\n","      logp_poe = logA0_poe + logp0_poe + self.logauth0\n","      logp_frost = logA1_frost + logp1_frost + self.logauth1\n","\n","      if logp_poe > logp_frost:\n","        auth.append(0)\n","      elif logp_poe < logp_frost:\n","        auth.append(1)\n","\n","    return(auth)\n","       \n"],"metadata":{"id":"9QVbb0KoJQuC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test = Classifier()\n","test.setup(arr_pi_poe_log, arr_pi_frost_log, arr_A_poe_log, arr_A_frost_log, p_poe_log,p_frost_log, dict_uni_words)\n","out = test.predict(lis_line_test)"],"metadata":{"id":"FHrqFjbqh4CT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean(np.array(lis_author_test) == np.array(out))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFMC8fjGkYX9","executionInfo":{"status":"ok","timestamp":1673789846396,"user_tz":0,"elapsed":5,"user":{"displayName":"Harry Martin","userId":"16278557778494234606"}},"outputId":"038d989b-e192-4e48-e103-04e8b89792c6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8163265306122449"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["cm = confusion_matrix(lis_author_test, out)\n","cm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qHfaUM9Hpn-m","executionInfo":{"status":"ok","timestamp":1673789950594,"user_tz":0,"elapsed":408,"user":{"displayName":"Harry Martin","userId":"16278557778494234606"}},"outputId":"6276a40e-cc76-45e5-ea34-8cf6e522fda4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 95,  88],\n","       [ 11, 345]])"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["# Unused Code"],"metadata":{"id":"qWfH_unqDdeV"}},{"cell_type":"code","source":["#Faster loop\n","%%time\n","\n","lis_uni_words = []\n","\n","for line in list(df_x_train):\n","  lis_uni_words += line.split()\n","\n","lis_uni_words = list(set(lis_uni_words))\n","\n","dict_uni_words_2 = {}\n","word_count = 0\n","\n","for word in lis_uni_words:\n","   word_count += 1\n","   dict_uni_words[word_count] = word"],"metadata":{"id":"_JjhHeTPDiBG"},"execution_count":null,"outputs":[]}]}